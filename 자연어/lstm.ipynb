{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c123d3d0-f331-4eb9-b0fd-8a8896615821",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "f5466612-2714-4314-b7fa-d579cf75bb8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('./data/ratings_train.txt', sep='\\t')\n",
    "test = pd.read_csv('./data/ratings_test.txt', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "4abd035f-c3c8-4e5f-8506-e40d9d551057",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "데이터 개수\n",
      "(150000, 3)\n",
      "nan 여부\n",
      "[False]\n",
      "중복 데이터 개수\n",
      "3818\n",
      "클래스별 개수\n",
      "label\n",
      "0    75173\n",
      "1    74827\n",
      "dtype: int64\n",
      "\n",
      "데이터 개수\n",
      "(50000, 3)\n",
      "nan 여부\n",
      "[False]\n",
      "중복 데이터 개수\n",
      "843\n",
      "클래스별 개수\n",
      "label\n",
      "0    24827\n",
      "1    25173\n",
      "dtype: int64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for table in (train, test):\n",
    "    print('데이터 개수')\n",
    "    print(table.shape)\n",
    "\n",
    "    print('nan 여부')\n",
    "    print(table.isnull()['label'].unique())\n",
    "\n",
    "    print('중복 데이터 개수')\n",
    "    print(table.shape[0] - table['document'].nunique())\n",
    "\n",
    "    print('클래스별 개수')\n",
    "    print(table.groupby('label').size())\n",
    "\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c38c6eee-1b52-4511-b622-d266e3029eff",
   "metadata": {},
   "source": [
    "# 실습\n",
    "1. document 컬럼에서 중복 값을 제거합니다\n",
    "1. document 컬럼에서 NaN 값을 제거합니다\n",
    "1. document 컬럼에서 한글, 공백을 제외한 모든 텍스트를 제거합니다\n",
    "1. 1~3번 전처리를 한 뒤, 비어있는 데이터를 제거합니다\n",
    "2. 전처리가 끝난 뒤, 데이터 개수 변화를 확인합니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f05946e1-b3d7-4c5a-bdd1-a7ed36625a01",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae14ca00-b227-460b-81ea-0f0073bc7991",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "805cc34e-0d02-4c25-b732-9ac2b1651572",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전처리 후 데이터 개수: (145393, 3)\n",
      "전처리 후 데이터 개수: (48852, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_16132\\2142432056.py:5: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  table['document'].replace('', float('nan'), inplace=True)\n"
     ]
    }
   ],
   "source": [
    "for table in (train, test):\n",
    "    table.drop_duplicates(subset=['document'], inplace=True)\n",
    "    table['document'] = table['document'].str.replace('[^가-힣ㄱ-ㅎㅏ-ㅣ ]','',regex=True)\n",
    "    table['document'] = table['document'].str.replace('[ +]','',regex=True)\n",
    "    table['document'].replace('', float('nan'), inplace=True)\n",
    "    table.dropna(how='any', inplace=True)\n",
    "\n",
    "    print('전처리 후 데이터 개수:', table.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62ff4027-6358-4bd1-88fe-984c8aac5aa2",
   "metadata": {},
   "source": [
    "# 형태소 분석\n",
    "1. 불용어 처리\n",
    "2. 한 글자 단어는 제외하도록 합니다\n",
    "3. train:test:valid=4000:2000:1000\n",
    "4. train:test:valid 데이터의 각 클래스별 비율 확인하기\n",
    "5. train set에서 등장하는 모든 단어 목록 확인하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "a2647835-05fd-4272-96ca-b983206e59ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Okt\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "okt = Okt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26959f84-fb4e-4b9c-b5f1-b3ba5f558641",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('../stopwords-ko.txt', encoding='utf8')\n",
    "stopwords = f.readlines()\n",
    "stopwords = [s[:-1] for s in stopwords]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "c9b62838-32b2-4440-b346-d77aa58979f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.reset_index(drop=True, inplace=True)\n",
    "test.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "85ab23c4-ae6b-4caf-b27f-15d324dfb30c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 4000/4000 [01:48<00:00, 36.98it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 2000/2000 [00:52<00:00, 38.31it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:25<00:00, 38.60it/s]\n"
     ]
    }
   ],
   "source": [
    "X_train = []\n",
    "y_train = []\n",
    "\n",
    "for i in tqdm(range(0,4000)):\n",
    "    sentence = train['document'][i]\n",
    "    y_train.append(train['label'][i])\n",
    "    tokenized = okt.morphs(sentence, stem=True)\n",
    "    stopwords_removed_sentence = [word for word in tokenized if not word in stopwords and len(word) >= 2]\n",
    "    if stopwords_removed_sentence == []: continue\n",
    "    X_train.append(stopwords_removed_sentence)\n",
    "\n",
    "X_test = []\n",
    "y_test = []\n",
    "\n",
    "for i in tqdm(range(0,2000)):\n",
    "    sentence = test['document'][i]\n",
    "    y_test.append(test['label'][i])\n",
    "    tokenized = okt.morphs(sentence, stem=True)\n",
    "    stopwords_removed_sentence = [word for word in tokenized if not word in stopwords and len(word) >= 2]\n",
    "    if stopwords_removed_sentence == []: continue\n",
    "    X_test.append(stopwords_removed_sentence)\n",
    "\n",
    "X_valid = []\n",
    "y_valid = []\n",
    "\n",
    "for i in tqdm(range(10000,11000)):\n",
    "    sentence = test['document'][i]\n",
    "    y_valid.append(test['label'][i])\n",
    "    tokenized = okt.morphs(sentence, stem=True)\n",
    "    stopwords_removed_sentence = [word for word in tokenized if not word in stopwords and len(word) >= 2]\n",
    "    if stopwords_removed_sentence == []: continue\n",
    "    X_valid.append(stopwords_removed_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "37a21eee-b286-4205-9c5a-37aa00182655",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 긍정 데이터 비율: 0.49925\n",
      "train 부정 데이터 비율: 0.50075\n",
      "\n",
      "test 긍정 데이터 비율: 0.5125\n",
      "test 부정 데이터 비율: 0.4875\n",
      "\n",
      "valid 긍정 데이터 비율: 0.495\n",
      "valid 부정 데이터 비율: 0.505\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for n in ('train', 'test', 'valid'):\n",
    "    t = globals()['y_' + n]\n",
    "    print(f'{n} 긍정 데이터 비율:', sum(t) / len(t))\n",
    "    print(f'{n} 부정 데이터 비율:', sum(np.array(t) == 0) / len(t))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5b91848-5707-4411-a0ec-5b0bab985878",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_list = []\n",
    "\n",
    "for sent in X_train:\n",
    "    for word in sent:\n",
    "        word_list.append(word)\n",
    "\n",
    "word_counts = Counter(word_list)\n",
    "\n",
    "len(word_counts)  # 고유한 단어 개수\n",
    "\n",
    "word_counts['사람']  # '사람'이라는 단어가 등장한 빈도\n",
    "\n",
    "vocab = sorted(word_counts, key=word_counts.get, reverse=True)\n",
    "\n",
    "vocab[:10]  # 빈출 단어 10개"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e16e9604-25c3-48e0-8295-948c31edc8ab",
   "metadata": {},
   "source": [
    "# 실습\n",
    "1. 빈출 단어 시각화\n",
    "2. 빈도가 3번 초과하지 않은 데이터는 제거\n",
    "* 다 하신 분들은 파이토치 설치 미리 해 두세요. cpu버전으로 설치하면 됩니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "a7a49f3f-50fa-4e9f-92ef-99ddfcc0b8fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import koreanize_matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "697b303b-ddeb-4d3a-9b72-9cb6223fb518",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_df = pd.DataFrame.from_dict(word_counts, orient='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "abf8b05d-77bc-4c9c-935d-fb9a4db03d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_df.sort_values(0, ascending=False, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "03256efa-c338-49c5-95a2-5db9024e552d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 400x200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.subplots(figsize=(4,2))\n",
    "sns.barplot(word_df.iloc[:10].T, color='darkorange')\n",
    "plt.xticks(rotation=90)\n",
    "plt.title('빈출 단어')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "1702933a-d699-4243-aaeb-e71054107558",
   "metadata": {},
   "outputs": [],
   "source": [
    "rm_list = []\n",
    "\n",
    "for k, v in word_counts.items():\n",
    "    if v <= 3:\n",
    "        rm_list.append(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "id": "68a5f0cc-b434-4c09-8042-9283a9b85436",
   "metadata": {},
   "outputs": [],
   "source": [
    "for X in ('X_train', 'X_test', 'X_valid'):\n",
    "    globals()[X] = [[x2 for x2 in x if x2 not in rm_list] for x in globals()[X]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "id": "e13804ac-593c-46e8-9c6f-93b0920302a1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for t in ('train', 'test', 'valid'):\n",
    "    rng = len(globals()['X_' + t])\n",
    "\n",
    "    globals()['X2_' + t] = []\n",
    "    globals()['y2_' + t] = []\n",
    "    for i in range(rng):\n",
    "        if globals()['X_' + t][i] == []:\n",
    "            continue\n",
    "        else:\n",
    "            globals()['X2_' + t].append(globals()['X_' + t][i])\n",
    "            globals()['y2_' + t].append(globals()['y_' + t][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "id": "1ce5bbee-b7a7-4b94-9efd-0f78881eedd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['영화', '보다', '하다', '없다', '이다', '좋다', '정말', '재밌다', '되다', '너무']"
      ]
     },
     "execution_count": 330,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_list = []\n",
    "\n",
    "for sent in X2_train:\n",
    "    for word in sent:\n",
    "        word_list.append(word)\n",
    "\n",
    "word_counts = Counter(word_list)\n",
    "\n",
    "len(word_counts)  # 고유한 단어 개수\n",
    "\n",
    "word_counts['사람']  # '사람'이라는 단어가 등장한 빈도\n",
    "\n",
    "vocab = sorted(word_counts, key=word_counts.get, reverse=True)\n",
    "\n",
    "vocab[:10]  # 빈출 단어 10개"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "id": "bd29e56f-f7d9-4c3b-a9f3-ebc48f66cb95",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_to_index = {}\n",
    "word_to_index['<PAD>'] = 0\n",
    "word_to_index['<UNK>'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "id": "44143fd6-4350-464b-8976-8dbcb6809e82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'<PAD>': 0, '<UNK>': 1}"
      ]
     },
     "execution_count": 326,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_to_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "id": "ea278919-53f1-4aa1-b4b8-d76d19316a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "for ind, word in enumerate(vocab):\n",
    "    word_to_index[word] = ind + 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "id": "a6131616-c42b-4a6b-8644-0f9ade54dd79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정수 인코딩\n",
    "def text_to_seq(X, word_to_index=word_to_index):\n",
    "    X_enc = []\n",
    "\n",
    "    for sent in X:\n",
    "        ind_seq = []\n",
    "\n",
    "        for word in sent:\n",
    "            try:\n",
    "                ind_seq.append(word_to_index[word])\n",
    "            except KeyError:\n",
    "                ind_seq.append(word_to_index['<UNK>'])\n",
    "\n",
    "        X_enc.append(ind_seq)\n",
    "\n",
    "    return X_enc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "id": "b792b2d4-9f82-454b-9ef6-16f9b773dcd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X2_train = text_to_seq(X2_train)\n",
    "X2_test = text_to_seq(X2_test)\n",
    "X2_valid = text_to_seq(X2_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "id": "1829900d-070f-42d8-a201-e8b9fcdc3161",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_to_word = {}\n",
    "\n",
    "for k, v in word_to_index.items():\n",
    "    index_to_word[v] = k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "id": "8025cf46-4f0d-4ae5-96fd-9a941811de1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 디코딩\n",
    "def seq_to_text(X, index_to_word=index_to_word):\n",
    "    X_dec = []\n",
    "\n",
    "    for sent in X:\n",
    "        ind_seq = []\n",
    "\n",
    "        for word in sent:\n",
    "            ind_seq.append(index_to_word[word])\n",
    "\n",
    "        X_dec.append(ind_seq)\n",
    "\n",
    "    return X_dec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "id": "b68536fd-e115-4a29-b4b4-2a8875395868",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_seq(sentences, max_len=30):\n",
    "    features = np.zeros((len(sentences), max_len), dtype=int)\n",
    "\n",
    "    for ind, sentence in enumerate(sentences):\n",
    "        if len(sentence) != 0:\n",
    "            features[ind, :len(sentence)] = np.array(sentence)[:max_len]\n",
    "\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "id": "17fcd1f9-1e89-4aff-8586-e52e8b53c35d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_pad = pad_seq(X2_train)\n",
    "X_test_pad = pad_seq(X2_test)\n",
    "X_valid_pad = pad_seq(X2_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "id": "d36a0267-6299-4b25-af22-de594df13862",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "id": "6201cccb-22c4-473e-9bec-854ee4a1c466",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "id": "24986752-af8e-4917-ad14-453f5ed27557",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_label_tensor = torch.tensor(np.array(y2_train))\n",
    "test_label_tensor = torch.tensor(np.array(y2_test))\n",
    "valid_label_tensor = torch.tensor(np.array(y2_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "id": "5e018aa2-f3c1-4452-9b8a-f4da0a7537cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextClassifier(torch.nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim):\n",
    "        super(TextClassifier, self).__init__()\n",
    "        self.embedding = torch.nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.lstm = torch.nn.LSTM(embedding_dim, hidden_dim, batch_first=True)\n",
    "        self.fc = torch.nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: batch_size, seq_length\n",
    "        embedded = self.embedding(x)\n",
    "\n",
    "        lstm_out, (hidden, cell) = self.lstm(embedded)\n",
    "\n",
    "        last_hidden = hidden.squeeze(0)\n",
    "        logits = self.fc(last_hidden)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "id": "847740a9-c656-4e70-8afc-61561765d508",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TextClassifier(\n",
       "  (embedding): Embedding(1374, 100)\n",
       "  (lstm): LSTM(100, 128, batch_first=True)\n",
       "  (fc): Linear(in_features=128, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 402,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_dim = 100\n",
    "hidden_dim = 128\n",
    "output_dim = 2  # binary\n",
    "learning_rate = 0.01\n",
    "num_epochs = 10\n",
    "vocab_size = len(word_to_index)\n",
    "\n",
    "model = TextClassifier(vocab_size, embedding_dim, hidden_dim, output_dim)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "id": "cac6360a-27c8-4695-86ed-ce0938ab454f",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_train = torch.tensor(X_train_pad).to(torch.int64)\n",
    "train_dataset = torch.utils.data.TensorDataset(encoded_train, train_label_tensor)\n",
    "train_dataloader = torch.utils.data.DataLoader(train_dataset, shuffle=True, batch_size=32)\n",
    "\n",
    "encoded_test = torch.tensor(X_test_pad).to(torch.int64)\n",
    "test_dataset = torch.utils.data.TensorDataset(encoded_test, test_label_tensor)\n",
    "test_dataloader = torch.utils.data.DataLoader(test_dataset, shuffle=True, batch_size=32)\n",
    "\n",
    "encoded_valid = torch.tensor(X_valid_pad).to(torch.int64)\n",
    "valid_dataset = torch.utils.data.TensorDataset(encoded_valid, valid_label_tensor)\n",
    "valid_dataloader = torch.utils.data.DataLoader(valid_dataset, shuffle=True, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "id": "ee180755-3647-4cb7-8c5b-37d31e23c4fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "id": "7a26a5cd-9434-400e-abda-e5707e2536ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_acc(logits, labels):\n",
    "    predicted = torch.argmax(logits, dim=1)\n",
    "    correct = (predicted == labels).sum().item()\n",
    "    total = labels.size(0)\n",
    "    acc = correct / total\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "id": "ca8f2059-14a6-4143-9a40-ca714a5323d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, valid_dataloader, criterion=criterion, device=device):\n",
    "    val_loss = 0\n",
    "    val_correct = 0\n",
    "    val_total = 0\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch_X, batch_y in valid_dataloader:\n",
    "            batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
    "\n",
    "            logits = model(batch_X)\n",
    "            loss = criterion(logits, batch_y)\n",
    "\n",
    "            val_loss += loss.item()\n",
    "            val_correct += calculate_acc(logits, batch_y) * batch_y.size(0)\n",
    "            val_total += batch_y.size(0)\n",
    "\n",
    "    val_acc = val_correct / val_total\n",
    "    val_loss /= len(valid_dataloader)\n",
    "\n",
    "    return val_loss, val_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "id": "debfc635-3368-4283-a2b4-0b30708d5f46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0 / 10\n",
      "train loss: 0.712, train acc.: 0.502\n",
      "valid loss: 0.695, valid acc.: 0.507\n",
      "best val.loss saved; valid loss: 0.695, valid acc.: 0.507\n",
      "epoch: 1 / 10\n",
      "train loss: 0.694, train acc.: 0.484\n",
      "valid loss: 0.694, valid acc.: 0.493\n",
      "best val.loss saved; valid loss: 0.694, valid acc.: 0.493\n",
      "epoch: 2 / 10\n",
      "train loss: 0.693, train acc.: 0.499\n",
      "valid loss: 0.694, valid acc.: 0.506\n",
      "epoch: 3 / 10\n",
      "train loss: 0.693, train acc.: 0.498\n",
      "valid loss: 0.693, valid acc.: 0.494\n",
      "best val.loss saved; valid loss: 0.693, valid acc.: 0.494\n",
      "epoch: 4 / 10\n",
      "train loss: 0.693, train acc.: 0.494\n",
      "valid loss: 0.694, valid acc.: 0.506\n",
      "epoch: 5 / 10\n",
      "train loss: 0.693, train acc.: 0.491\n",
      "valid loss: 0.694, valid acc.: 0.494\n",
      "epoch: 6 / 10\n",
      "train loss: 0.692, train acc.: 0.502\n",
      "valid loss: 0.696, valid acc.: 0.495\n",
      "epoch: 7 / 10\n",
      "train loss: 0.692, train acc.: 0.513\n",
      "valid loss: 0.702, valid acc.: 0.486\n",
      "epoch: 8 / 10\n",
      "train loss: 0.691, train acc.: 0.526\n",
      "valid loss: 0.694, valid acc.: 0.510\n",
      "epoch: 9 / 10\n",
      "train loss: 0.676, train acc.: 0.579\n",
      "valid loss: 0.711, valid acc.: 0.499\n"
     ]
    }
   ],
   "source": [
    "best_val_loss = float('inf')\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss, train_correct, train_total = 0, 0, 0\n",
    "    model.train()\n",
    "\n",
    "    for batch_X, batch_y in train_dataloader:\n",
    "        batch_x, batch_y = batch_X.to(device), batch_y.to(device)\n",
    "        logits = model(batch_X)\n",
    "        loss = criterion(logits, batch_y)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        train_correct += calculate_acc(logits, batch_y) * batch_y.size(0)\n",
    "        train_total += batch_y.size(0)\n",
    "\n",
    "    train_acc = train_correct / train_total\n",
    "    train_loss /= len(train_dataloader)\n",
    "\n",
    "    val_loss, val_acc = evaluate(model, valid_dataloader)\n",
    "\n",
    "    print(f'epoch: {epoch+1} / {num_epochs}')\n",
    "    print(f'train loss: {train_loss:.3f}, train acc.: {train_acc:.3f}')\n",
    "    print(f'valid loss: {val_loss:.3f}, valid acc.: {val_acc:.3f}')\n",
    "\n",
    "    if val_loss < best_val_loss:\n",
    "        print(f'best val.loss saved; valid loss: {val_loss:.3f}, valid acc.: {val_acc:.3f}')\n",
    "        best_val_loss = val_loss\n",
    "        torch.save(model.state_dict(), './best_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "id": "cd0fd654-1d18-4bf4-bfa8-9c2050f0adc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_16132\\3794482924.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load('./best_model.pth'))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 432,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('./best_model.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "id": "c8139612-4d34-406a-aa58-fc11c0e24987",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TextClassifier(\n",
       "  (embedding): Embedding(1374, 100)\n",
       "  (lstm): LSTM(100, 128, batch_first=True)\n",
       "  (fc): Linear(in_features=128, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 434,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "id": "17bb035a-4380-4c48-837a-c912a151ea0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_acc = evaluate(model, test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "id": "703ae6b1-1cbe-48e4-b2ee-1d469bcfdcfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6933677513753215 0.5159655347187024\n"
     ]
    }
   ],
   "source": [
    "print(test_loss, test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "id": "6144af87-95fb-4b72-ac46-1109ede02bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(text, model, word_to_index=word_to_index):\n",
    "    model.eval()\n",
    "\n",
    "    tokens = okt.morphs(text, stem=True)\n",
    "    tokens = [word for word in tokens if not word in stopwords]\n",
    "    token_indices = [word_to_index.get(token, 1) for token in tokens]\n",
    "\n",
    "    input_tensor = torch.tensor([token_indices], dtype=torch.long).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        logits = model(input_tensor)\n",
    "\n",
    "    pred_ind = torch.argmax(logits, dim=1)\n",
    "\n",
    "    return pred_ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "id": "a3c9d9c3-6f95-4222-843a-a20089c4e450",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "부정적 리뷰\n"
     ]
    }
   ],
   "source": [
    "if int(predict('싫어요', model)) == 0:\n",
    "    print('부정적 리뷰')\n",
    "else:\n",
    "    print('긍정적 리뷰')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64fbb4cd-c221-4606-8965-177cbf56a792",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
